{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/managed/manage_retrieval_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Retriever Benchmark\n",
    "\n",
    "In this notebook, we will compare different retrieval services including\n",
    "* Google Semantic Retrieval\n",
    "* LlamaIndex default Retrieval\n",
    "* Vectara Managed Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index\n",
    "%pip install \"google-ai-generativelanguage>=0.4,<=1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Authentication Overview\n",
    "\n",
    "The Google Semantic Retriever API lets you perform semantic search on your own data. Since it's **your data**, this needs stricter access controls than API Keys. Authenticate with OAuth through service accounts or through your user credentials. This quickstart uses a simplified authentication approach for a testing environment, and service account setup are typically easier to start. For a production environment, learn about [authentication and authorization](https://developers.google.com/workspace/guides/auth-overview) before choosing the [access credentials](https://developers.google.com/workspace/guides/create-credentials#choose_the_access_credential_that_is_right_for_you) that are appropriate for your app.\n",
    "\n",
    "Demo recording for authenticating using service accounts: [Demo](https://drive.google.com/file/d/199LzrdhuuiordS15MJAxVrPKAwEJGPOh/view?usp=sharing)\n",
    "\n",
    "**Note**: At this time, the Google Generative AI Semantic Retriever API is [only available in certain regions](https://ai.google.dev/available_regions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication (Option 1): OAuth using service accounts\n",
    "\n",
    "Google Auth [service accounts](https://cloud.google.com/iam/docs/service-account-overview) let an application authenticate to make authorized Google API calls. To OAuth using service accounts, follow the steps below:\n",
    "\n",
    "1. Enable the `Generative Language API`: [Documentation](https://developers.generativeai.google/tutorials/oauth_quickstart#1_enable_the_api)\n",
    "\n",
    "1. Create the Service Account by following the [documentation](https://developers.google.com/identity/protocols/oauth2/service-account#creatinganaccount).\n",
    "\n",
    " * After creating the service account, generate a service account key.\n",
    "\n",
    "1. Upload your service account file by using the file icon on the left sidebar, then the upload icon, as shown in the screenshot below.\n",
    "\n",
    "<img width=400 src=\"https://developers.generativeai.google/tutorials/images/colab_upload.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from llama_index.indices.managed.google.generativeai import (\n",
    "    GoogleIndex,\n",
    "    set_google_config,\n",
    ")\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    \"service_account_key.json\",\n",
    "    scopes=[\n",
    "        \"https://www.googleapis.com/auth/cloud-platform\",\n",
    "        \"https://www.googleapis.com/auth/generative-language.retriever\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "set_google_config(auth_credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication (Option 2): OAuth using user credentials\n",
    "\n",
    "Please follow [OAuth Quickstart](https://developers.generativeai.google/tutorials/oauth_quickstart) to setup OAuth using user credentials. Below are overview of steps from the documentation that are required.\n",
    "\n",
    "1. Enable the `Generative Language API`: [Documentation](https://developers.generativeai.google/tutorials/oauth_quickstart#1_enable_the_api)\n",
    "\n",
    "1. Configure the OAuth consent screen: [Documentation](https://developers.generativeai.google/tutorials/oauth_quickstart#2_configure_the_oauth_consent_screen)\n",
    "\n",
    "1. Authorize credentials for a desktop application: [Documentation](https://developers.generativeai.google/tutorials/oauth_quickstart#3_authorize_credentials_for_a_desktop_application)\n",
    "  * If you want to run this notebook in Colab start by uploading your\n",
    "`client_secret*.json` file using the \"File > Upload\" option.\n",
    "\n",
    " * Rename the uploaded file to `client_secret.json` or change the variable `client_file_name` in the code below.\n",
    "\n",
    "<img width=400 src=\"https://developers.generativeai.google/tutorials/images/colab_upload.png\">\n",
    "\n",
    "\n",
    "**Note**: At this time, the Google Generative AI Semantic Retriever API is [only available in certain regions](https://developers.generativeai.google/available_regions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace TODO-your-project-name with the project used in the OAuth Quickstart\n",
    "project_name = \"TODO-your-project-name\"  #  @param {type:\"string\"}\n",
    "# Replace TODO-your-email@gmail.com with the email added as a test user in the OAuth Quickstart\n",
    "email = \"ht@runllama.ai\"  #  @param {type:\"string\"}\n",
    "# Replace client_secret.json with the client_secret_* file name you uploaded.\n",
    "client_file_name = \"client_secret.json\"\n",
    "\n",
    "# IMPORTANT: Follow the instructions from the output - you must copy the command\n",
    "# to your terminal and copy the output after authentication back here.\n",
    "!gcloud config set project $project_name\n",
    "!gcloud config set account $email\n",
    "\n",
    "# NOTE: The simplified project setup in this tutorial triggers a \"Google hasn't verified this app.\" dialog.\n",
    "# This is normal, click \"Advanced\" -> \"Go to [app name] (unsafe)\"\n",
    "!gcloud auth application-default login --no-browser --client-id-file=$client_file_name --scopes=\"https://www.googleapis.com/auth/generative-language.retriever,https://www.googleapis.com/auth/cloud-platform\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will provide you with a URL, which you should enter into your local browser.\n",
    "Follow the instruction to complete the authentication and authorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Paul Graham Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth for the query `\"which program did this author attend?\"`\n",
    "\n",
    "Wiki Link: https://en.wikipedia.org/wiki/Paul_Graham_(programmer)\n",
    "\n",
    "Answer from Wiki:\n",
    "```\n",
    "Graham and his family moved to Pittsburgh, Pennsylvania in 1968, where he later attended Gateway High School. Graham gained interest in science and mathematics from his father who was a nuclear physicist.[8]\n",
    "\n",
    "Graham received a Bachelor of Arts with a major in philosophy from Cornell University in 1986.[9][10][11] He then received a Master of Science in 1988 and a Doctor of Philosophy in 1990, both in computer science from Harvard University.[9][12]\n",
    "\n",
    "Graham has also studied painting at the Rhode Island School of Design and at the Accademia di Belle Arti in Florence.[9][12]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Semantic Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_API_KEY = \"\"  # add your GOOGLE API key here\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.indices.managed.google.generativeai import GoogleIndex\n",
    "\n",
    "# Create a Google corpus.\n",
    "index = GoogleIndex.create_corpus(display_name=\"My first corpus!\")\n",
    "print(f\"Newly created corpus ID is {index.corpus_id}.\")\n",
    "\n",
    "# Ingestion.\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n",
    "index.insert_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Semantic Retrieval: Using default query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newly created corpus ID is 18e88264-68af-4c5d-a970-a3c0f9d18452.\n",
      "The author attended Cornell, MIT, and Yale.\n"
     ]
    }
   ],
   "source": [
    "# Querying.\n",
    "# print(f\"Newly created corpus ID is {index.corpus_id}.\")\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"which program did this author attend?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Semantic Retrieval: Using `Verbose` Answer Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author attended Cornell University for their undergraduate studies, where they majored in Computer Science and minored in Philosophy. They then attended Harvard University for their graduate studies, where they studied Computer Science and wrote their dissertation on Lisp programming.\n"
     ]
    }
   ],
   "source": [
    "from google.ai.generativelanguage import (\n",
    "    GenerateAnswerRequest,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    # Extra parameters specific to the Google query engine.\n",
    "    temperature=0.7,\n",
    "    answer_style=GenerateAnswerRequest.AnswerStyle.VERBOSE,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Which program did this author attend?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Semantic Retrieval: Using `Abstractive` Answer Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This author attended Cornell University and Harvard University.\n"
     ]
    }
   ],
   "source": [
    "from google.ai.generativelanguage import (\n",
    "    GenerateAnswerRequest,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    # Extra parameters specific to the Google query engine.\n",
    "    temperature=0.7,\n",
    "    answer_style=GenerateAnswerRequest.AnswerStyle.ABSTRACTIVE,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Which program did this author attend?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Semantic Retrieval: Using `Extractive` Answer Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornell\n"
     ]
    }
   ],
   "source": [
    "from google.ai.generativelanguage import (\n",
    "    GenerateAnswerRequest,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    # Extra parameters specific to the Google query engine.\n",
    "    temperature=0.7,\n",
    "    answer_style=GenerateAnswerRequest.AnswerStyle.EXTRACTIVE,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Which program did this author attend?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Semantic Retrieval: Advanced Retrieval with LlamaIndex Reranking\n",
    "* Gemini as Reranker LLM\n",
    "* Adopt Abstractive Answer Style for Response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.response_synthesizers.google.generativeai import (\n",
    "    GoogleTextSynthesizer,\n",
    ")\n",
    "from llama_index.vector_stores.google.generativeai import (\n",
    "    GoogleVectorStore,\n",
    "    google_service_context,\n",
    ")\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.llms import Gemini\n",
    "from llama_index.postprocessor import LLMRerank\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.embeddings import GeminiEmbedding\n",
    "\n",
    "\n",
    "# Set up the query engine with a reranker.\n",
    "\n",
    "response_synthesizer = GoogleTextSynthesizer.from_defaults(\n",
    "    temperature=0.7, answer_style=GenerateAnswerRequest.AnswerStyle.ABSTRACTIVE\n",
    ")\n",
    "\n",
    "embed_model = GeminiEmbedding(\n",
    "    model_name=\"models/embedding-001\", api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "reranker = LLMRerank(\n",
    "    top_n=5,\n",
    "    service_context=ServiceContext.from_defaults(\n",
    "        llm=Gemini(api_key=GOOGLE_API_KEY), embed_model=embed_model\n",
    "    ),\n",
    ")\n",
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[reranker],\n",
    ")\n",
    "\n",
    "# Query for better result!\n",
    "response = query_engine.query(\"Which program did this author attend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author attended Cornell, Harvard, RISD, and the Accademia di Belli Arti.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex Default Baseline with OpenAI embedding and GPT as LLM for Synthesizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OPENAI_API_TOKEN = \"sk-\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, StorageContext, ServiceContext\n",
    "from llama_index.vector_stores import QdrantVectorStore\n",
    "from llama_index import StorageContext\n",
    "import qdrant_client\n",
    "\n",
    "\n",
    "# Create a local Qdrant vector store\n",
    "client = qdrant_client.QdrantClient(path=\"qdrant_retrieval_10\")\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"collection\")\n",
    "qdrant_index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(chunk_size=256)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author attended the Accademia di Belli Arti.\n"
     ]
    }
   ],
   "source": [
    "query_engine = qdrant_index.as_query_engine()\n",
    "response = query_engine.query(\"Which program did this author attend?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex Default Configuration with LLM Reranker and Tree Summarize for Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import get_response_synthesizer\n",
    "\n",
    "\n",
    "reranker = LLMRerank(top_n=4, service_context=service_context)\n",
    "retriever = index.as_retriever(similarity_top_k=4)\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=get_response_synthesizer(\n",
    "        service_context=service_context,\n",
    "        response_mode=\"tree_summarize\",\n",
    "    ),\n",
    "    node_postprocessors=[reranker],\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Which program did this author attend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author attended the BFA program at RISD (Rhode Island School of Design).\n"
     ]
    }
   ],
   "source": [
    "# for r in response.source_nodes:\n",
    "#     print(r.text)\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectara Managed Index and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.indices import VectaraIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectara_customer_id = \"\"\n",
    "vectara_corpus_id = \"\"\n",
    "vectara_api_key = \"\"\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n",
    "vectara_index = VectaraIndex.from_documents(\n",
    "    documents,\n",
    "    vectara_customer_id=vectara_customer_id,\n",
    "    vectara_corpus_id=vectara_corpus_id,\n",
    "    vectara_api_key=vectara_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author attended Cornell University [1] and Harvard University [2]. They applied to RISD, but ended up attending Rhode Island School of Design (RISD) [3]. Additionally, the author was in a PhD program in computer science [5]. The search results indicate that the author had a diverse academic background and pursued different programs at various institutions.\n"
     ]
    }
   ],
   "source": [
    "vectara_query_engine = vectara_index.as_query_engine(similarity_top_k=5)\n",
    "response = vectara_query_engine.query(\"Which program did this author attend?\")\n",
    "# texts = [t.node.text for t in response]\n",
    "# print(\"\\n--\\n\".join(texts))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
